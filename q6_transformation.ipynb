{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5, Question 6: Data Transformation\n",
    "\n",
    "**Points: 20**\n",
    "\n",
    "Transform and engineer features from the clinical trial dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 patients\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import utilities\n",
    "from q3_data_utils import load_data, clean_data, transform_types, create_bins, fill_missing\n",
    "\n",
    "df = load_data('data/clinical_trial_raw.csv')\n",
    "print(f\"Loaded {len(df)} patients\")\n",
    "\n",
    "# Prewritten visualization functions for transformation analysis\n",
    "def plot_distribution(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a histogram of a numeric series.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with numeric data\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.hist(bins=30)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_value_counts(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a bar chart of value counts.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with value counts\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.plot(kind='bar')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Type Conversions (5 points)\n",
    "\n",
    "1. Convert 'enrollment_date' to datetime using the `transform_types()` utility\n",
    "2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "3. Ensure all numeric columns are proper numeric types\n",
    "4. Display the updated dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id                    object\n",
      "age                            int64\n",
      "sex                         category\n",
      "bmi                          float64\n",
      "enrollment_date       datetime64[ns]\n",
      "systolic_bp                  float64\n",
      "diastolic_bp                 float64\n",
      "cholesterol_total            float64\n",
      "cholesterol_hdl              float64\n",
      "cholesterol_ldl              float64\n",
      "glucose_fasting              float64\n",
      "site                        category\n",
      "intervention_group          category\n",
      "follow_up_months               int64\n",
      "adverse_events                 int64\n",
      "outcome_cvd                   object\n",
      "adherence_pct                float64\n",
      "dropout                       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TODO: Type conversions\n",
    "# 1. Use transform_types() to convert enrollment_date to datetime\n",
    "# 2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "# 3. Ensure all numeric columns are proper numeric types\n",
    "# 4. Display the updated dtypes using df.dtypes\n",
    "df = transform_types(df, type_map = {'enrollment_date' : 'datetime'})\n",
    "categorical_cols = ['site', 'intervention_group', 'sex']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering (8 points)\n",
    "\n",
    "Create these new calculated columns:\n",
    "\n",
    "1. `cholesterol_ratio` = cholesterol_ldl / cholesterol_hdl\n",
    "2. `bp_category` = categorize systolic BP:\n",
    "   - 'Normal': < 120\n",
    "   - 'Elevated': 120-129\n",
    "   - 'High': >= 130\n",
    "3. `age_group` using `create_bins()` utility:\n",
    "   - Bins: [0, 40, 55, 70, 100]\n",
    "   - Labels: ['<40', '40-54', '55-69', '70+']\n",
    "4. `bmi_category` using standard BMI categories:\n",
    "   - Underweight: <18.5\n",
    "   - Normal: 18.5-24.9\n",
    "   - Overweight: 25-29.9\n",
    "   - Obese: >=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate cholesterol ratio\n",
    "df['cholesterol_ratio'] = df['cholesterol_ldl'] / df['cholesterol_hdl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Categorize blood pressure\n",
    "df = create_bins(df,\n",
    "    'systolic_bp',\n",
    "    bins=[0, 120, 130, 999],\n",
    "    labels=['Normal', 'Elevated', 'High'],\n",
    "    new_column = 'bp_category'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `create_bins()` function has an optional `new_column` parameter. If you don't specify it, the new column will be named `{original_column}_binned`. You can use `new_column='age_group'` to give it a custom name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create age groups\n",
    "df = create_bins(df,\n",
    "    'age',\n",
    "    bins=[0, 40, 55, 70, 100],\n",
    "    labels=['<40', '40-54', '55-69', '70+'],\n",
    "    new_column = 'age_group'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create BMI categories\n",
    "df = create_bins(df,\n",
    "    'bmi',\n",
    "    bins=[0, 18.5, 24.9, 29.9, 999],\n",
    "    labels=['Underweight', 'Normal', 'Overweight', 'Obese'],\n",
    "    new_column = 'bmi_category'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: String Cleaning (2 points)\n",
    "\n",
    "If there are any string columns that need cleaning:\n",
    "1. Convert to lowercase\n",
    "2. Strip whitespace\n",
    "3. Replace any placeholder values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: String cleaning\n",
    "for col in df:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: One-Hot Encoding (5 points)\n",
    "\n",
    "Create dummy variables for categorical columns:\n",
    "1. One-hot encode 'intervention_group' using `pd.get_dummies()`\n",
    "2. One-hot encode 'site'\n",
    "3. Drop the original categorical columns\n",
    "4. Show the new shape and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20) ['patient_id', 'age', 'sex', 'bmi', 'enrollment_date', 'systolic_bp', 'diastolic_bp', 'cholesterol_total', 'cholesterol_hdl', 'cholesterol_ldl', 'glucose_fasting', 'follow_up_months', 'adverse_events', 'outcome_cvd', 'adherence_pct', 'dropout', 'cholesterol_ratio', 'bp_category', 'age_group', 'bmi_category']\n"
     ]
    }
   ],
   "source": [
    "# TODO: One-hot encoding\n",
    "df_int_group = pd.get_dummies(df['intervention_group'], dtype = 'int64')\n",
    "df.drop('intervention_group', axis=1, inplace=True)\n",
    "df_transformed = pd.concat([df, df_int_group], axis=1)\n",
    "df_site = pd.get_dummies(df['site'], prefix='site', dtype = 'int64')\n",
    "df.drop('site', axis=1, inplace=True)\n",
    "df_transformed = pd.concat([df, df_site], axis=1)\n",
    "print(df.shape, df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save Transformed Data\n",
    "\n",
    "Save the fully transformed dataset to `output/q6_transformed_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save transformed data\n",
    "df_transformed.to_csv('output/q6_transformed_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci-217 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
